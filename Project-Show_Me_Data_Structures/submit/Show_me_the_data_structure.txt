# Problem 1

##Design

This implementation is done using an OrderedDict which is a high-level module. Under the hood, the implementation
is a double LinkedList and a dictionary. the get () method is used to retrieve item using a provided key while the 
the set method sets new value is the key is not already present in the dictionary.


## Time Complexity
The use of get () and set method all looks checks if a key is present in the dictionary. With that in mind, code runs
in constant time in the order of O(1) got both the get() and set() methods at average case and O(1) at the worst case as there is no possibility of hash collision.

##Space complexity
Space complexity takes the order of in O(n) where _n_ in this case is the capacity of the cache initialized. Average case would be 
constant time is the capacity is one hence order of 0(1) with the worst case as 0(n) where _n_ is the cache capacity.

# Problem 2

## Design

The data structure under the hood is a tree with start of the directory as the root and sub-directories spreading to new branches.

This is implemented using recursion process, on a visit of each folder, and searches for a match before moving to the next folder. This is a classic 
case of a depth first search. The process is continued recursively until all the branches have been visited 

## Time complexity, 
It takes linear time O(n). 
This is because we must visit each leaf at every branch of the tree and therefore will depends on the number of leaves and branches 
on the tree. Average case would be O (1) where the tree only had a root (a folder in this case) and O(n) where _n_ is the total number of
folders and files which the algorithm visits at least once in the worst-case.

## Space complexity
This depends on the numbers of nested directories and sub-directories that will have to be printed out. Just as with the time complexity,
average case will be in the order of O(1) and the worst-case O(n) where n is the number of returns the function does.

# Problem 3

## Design:
This is implemented by utilizing three 4 different classes namely, Node, Queue, Tree and a Huffman Encoder giving a clean developmental approach.
Two different data structures are used in this solution namely 

* Node -> Leaf node for each character of the text containing the occurring frequency of that character.
 
* Queue - > used in storing elements on a In First Out (FIFO) basis and their frequency in the input text.

* Tree -> A tree is built using the data in the queue depending in the frequency of the elements with all the values stored at the leaves of the tree.

* Huffman Encoder - > Does the encoding and decoding of the input characters


##Complexity

### Time Complexity
* Encoding:

The encoding process takes in every single element in string provided and its frequency. But the key part of this process is preparing the 
original text before even the process starts. The fuse method in the Queue combines the two nodes of characters and their frequency and 
elements must be sorted in a while every time the fuse is run. This runs in the order of O(n*nlogn)


* Decoding:

For every encoded symbol you must traverse the tree in order to decode that symbol. The tree contains k nodes and, on average, 
it takes O(logk) node visits to decode a symbol. So the time complexity would be O(n log k).

## Space Complexity
* Encoding:
The space complexity takes the order of O(n) where n is the number of characters in the input string. 

* Decoding:
Space complexity for decoding is in the order of O(n) where  _n_ is the length of the decoded text.


# Problem 4

This solution is implemented using a tree data structure. The Group acts as the root and sub-group as the branches and members of the group as
leaves. 

## Complexity
The time complexity is this implementation is dependent on the number of iterations run by the algorithm, in terms of number of groups
and users in the group therefore taking a linear time O(n). The leaves are visited using depth first search and the deeper the leave is the
longer it takes hence  _n_ in this case will the number of leaves and how long it takes to get to all leaves in every branch.


Space complexity also depends on the number of outputs from the function hence O(n).The final data structure for the groups or members is a list 
and therefore _n_ in this will depends on the number of groups or members available.

# Problem 5

Design:

Key design for this problem is a LinkedList
This implementation includes a Blockchain class with an additional method called update block which updates the current block with a value.

## Complexity
##Time Complexity

The Time complexity of append method is O(1) as it runs in constant time as the only pace a new block can be added is at the end 
of the chain. The worst-case scenario would be O(1) as a block only gets added at the end of the chain with the operation taking
a constant time.
The second method for getting the size runs in the order of O(n) where _n_ in this case is the number of blocks in the chain.

Converting the blockchain to list will also depend on how long the block is and therefore will run in the order of O(n) where _n_ is the 
length of the block.
 

## Space Complexity
Space complexity is in the order of O(n*k) where n is the length of characters in the input sting at _k_ is the hash function. After hashing, 
the space complexity of the Blockchain gets to the order of O(n) where n is the length of the chain.

# Problem 6 

## Design:
This problem is solved using several data structures. 

* Sets: Unordered datasets where elements are not repeated. In this problem, sets are used to create 
a new LinkedList where no elements are repeated. 


* Union: Takes the two input lists as sets and joins them together in a single LinkedList

* Intersection: Finds a new list of elements that are present in both linkedlists1 and linkedlist1 that have 
been joined together.


## Complexity

## Time complexity
* Union:

Union operations takes in a new list and creates a set of elements from each LinkedList. 
The second part of the union is the creation of a new list based on the set created in the previous step. Here,
while the process still takes linear time, the good news here is that the length of the list depends on the 
number of unique elements with average case of a constant time 0(1) if there only one element and worse case at 0(n) 
where n is the total number of different unique elements in the set.

* Intersection: 

The intersection process is having a nested if statement that compares two lists together and therefore length of list1
compared with every element in the second list resulting into an order of O(n) at the worst-case and second _n is the length of list2.


The intersection process compares the two list checking each to find out if there are similar elements and building another list.
This runs at the worst-case in O(n) in creating the final LinkedList. _n_ in this case is the length of the final intersection 
linked list.



### Space Complexity

* Union:
For space time complexity, the union process creates three created thereby taking the order of O(3n) resulting in an order of 
O(n). The _n_ here refers to the number of elements in each list. 

* Intersection:
The intersection also creates three separate tables with the two temporary set tables and a final intersection table thereby 
taking the order of O(3n) resulting into an order of 0(n) where _n_ refers to the list of similar elements in intersection.
