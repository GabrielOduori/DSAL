# Problem 1

##Design

This implementation is done using an OrderedDict which is a high level module. Under the hood, the implementation
is a double linkedlist and a dictonary. the get() method is used to retreave item using a provided key while the 
the set method sets new value is the key is not already present in the dictionary.


## Time Complexity
The use of get() and set method all looks checks if a key is present in the dictionay. With that in mind, code runs
in constant time in the order of O(1) got both the get() and set() methods at average case and O(1) at the worst case 
as there is no possbility of hask collision.

##Space complexity
Space comlexity takaes the order of in O(n) where _n_ in this case is the capacity of the cache initalized. Average case would be 
constant time is the capcity is one hence order of 0(1) with the worst case as 0(n) where _n_ is the cache capacity.

# Problem 2

## Design

The data structure under the hood is a tree with start of the directory as the root and sub-directories speading to new branches.

This is implemented using recursion process, on a visit of each folder, and searches for a match before moving to the next folder. This is a classic 
case of a depth first search. The process is continued recursively until all the branches have been visited 

## Time complexity, 
It takes linear time O(n). 
This is because we have to visit each leaf at every branch of the tree and therefore will depends on the number of leaves and branches 
on the tree. Average case would be O(1) where the tree only had a root (a folder in this case) and O(n) where _n_ is the total number of
folders and files which the algotithm visits at least once in the worst-case.

## Space complexity
This depends on the numbers of nested directorories and sub-directorirs that will have to be printed out. Just as with the time complexity,
average case will ne in the order of O(1) and the worse case O(n) where n is the number of returns the function does.

# Problem 3

## Design:
This is implemented by utilizing three 4 different classes namely, Node, Queue, Tree and a HuffmanEncoder giving a clean developmental approach.
Two different data structures are used in this solutin namely 

* Node -> Leaf node for each character of the text containing the occurring frequency of that character.
 
* Queue - > used in storing elements on a In First Out (FIFO) basis and their freequncy in the inuput text.

* Tree -> A tree is built using the data in the queue depending in the freequency of the elements with all the values stored at the leaves of the tree.

* HuffmanEncoder - > Does the encoding and decoding of the input characters


##Complexity

### Time Complexity
* Encoding:

The encoding process takes in every single element in string ptovided and its freequency. But the key part of this process is preparing the 
original text before even the process starts. The fuse method in the Queue combines the two nodes of charaters and their frequency and 
elements have to be sorted in a while every time time the fuse is run. This runs in the order of O(n*nlogn)


* Decoding:

For every encoded symbol you have to traverse the tree in order to decode that symbol. The tree contains k nodes and, on average, 
it takes O(logk) node visits to decode a symbol. So the time complexity would be O(n log k).

## Space Complexity
* Encoding:
The space complexity takes the order of O(n) where n is the number of characters in the input string. 

* Decoding:
Space complexity for decoding is in the order of O(n) where  _n_ is the length of the decoded text.


# Problem 4

This solution is implemented usig a tree data structure.The Group acts as a the root and sub-group as the branches and members of the group as
leaves. 

## Complexity
The time complexity is this implementation is dependent on the number of iterations run by the algorithm, in terms of number of groups
and users in the group therefore taking a linear time O(n). The leaves are visited using depth first search and the deepender the leave is the
longer it takes hence  _n_ in this case will the number of leaves and how long it takes to get to all leaves in every branch.


Space complexity also depends on the number of outputs from the function hence O(n).The final data structure for the groups or members is a list 
and therefore _n_ in this will depends on the number of groups or members available.

# Problem 5

Design:

Key design for this prolem is a linkedlist
This implementation includes a Blockchain class with an additional method called update block which updates the current block with a value.

## Complexity
##Time Complexity

The Time complexity of update_block is O(1) as it runs in constant time as the only pace a new block can be inserted is at the end 
of the chain. The worst-case scenerio would be O(n) where _n_ refers to the number of blocks being added to the chain.
The second method for getting the size runs in the order of O(n) where _n_ in thi case is the number of blocks in the chain.

COnverting the blockchain to list will also depend on how long the block is and therefore will run in the order of O(n) where _n_ is the 
length of the block.
 

## Space Complexity
Space complexity is in the order of O(n*k) where n is the length of charaters in the input sting at _k_ is the hash function. After hashing, 
the space complexity of the Blockchain gets to the order of O(n) where n is the length of the chain.

# Problem 6 

## Design:
This problem is solved using a number of data structures. 

* Sets: Unordered datasets where elements are not repeated. In this problem, sets are used to breate 
a new linklist where no elements are repeated. 


* Union: Takes the  two input lists as sets and joins them together in a single linklist

* Insersection: Finds a new list of elements that are present in both linkedlists1 and linkedlist1 that have 
been joined together.


## Complexity

## Time complexity
* Union:

Union operations takes in a new list and creates a set of elements from each linkedlist. 
The second part of the union is the creation of a new list based on the set created in the previous step. Here,
while the process still takes linear time, the good news here is that the length of the list depends on the 
number of unique elements with average case of a constant time 0(1) if there only one element and worse case at 0(n) 
where n is the total number of different unique elements in the set.

* Intersection: 
The intersection process is having a nested if statement that compares two lists together and therefore length of list1
compared with every element in the second list resulting into an order of O(n^n) where the first _n_ in the lenngth of list1
and second _n is the length of list2.

### Space Complexity

* Union:
For space time complexity, the union process creates three created thereby taking the order of O(3n) resulting in an order of 
O(n). The _n_ here refers to the number of elements in each list. 

* Intersection:
The intersection also crates three seprate tables with the two temporary set tables and a final union tabe thereby 
taking the order of O(3n) resulting into an order of 0(n) where _n_ refers to the list of similar elemnts in both the 
in both the lists.